# ğŸ“ Model EÄŸitim KÄ±lavuzu

Bu dokÃ¼manda Ã¶zel hayvan tespit modeli eÄŸitimi anlatÄ±lmaktadÄ±r.

---

## ğŸ“‹ Genel BakÄ±ÅŸ

YOLOv8 modelini kendi veri setinizle fine-tune ederek:
- Belirli hayvan tÃ¼rlerini daha iyi tespit edebilir
- Ã–zel ortam koÅŸullarÄ±na uyum saÄŸlayabilir
- Yeni sÄ±nÄ±flar ekleyebilirsiniz

---

## ğŸ“ Veri Seti HazÄ±rlÄ±ÄŸÄ±

### KlasÃ¶r YapÄ±sÄ±

```
data/datasets/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”œâ”€â”€ image_101.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ image_001.txt
â”‚   â”‚   â”œâ”€â”€ image_002.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ ...
â””â”€â”€ dataset.yaml
```

### YOLO Label FormatÄ±

Her gÃ¶rÃ¼ntÃ¼ iÃ§in aynÄ± isimde `.txt` dosyasÄ±:

```
# class_id x_center y_center width height
# TÃ¼m deÄŸerler 0-1 arasÄ±nda normalize edilmiÅŸ

0 0.5 0.5 0.3 0.4
1 0.2 0.7 0.15 0.25
```

### Dataset YAML DosyasÄ±

```yaml
# data/datasets/dataset.yaml

path: /path/to/data/datasets
train: images/train
val: images/val
test: images/test

# SÄ±nÄ±flar
names:
  0: cow
  1: sheep
  2: goat
  3: horse

# SÄ±nÄ±f sayÄ±sÄ±
nc: 4
```

---

## ğŸ–¼ï¸ Veri Toplama

### 1. Video'dan Frame Ã‡Ä±karma

```python
import cv2
import os

def extract_frames(video_path, output_dir, interval=30):
    """
    Video'dan belirli aralÄ±klarla frame Ã§Ä±karÄ±r.
    
    Args:
        video_path: Video dosya yolu
        output_dir: Ã‡Ä±ktÄ± klasÃ¶rÃ¼
        interval: KaÃ§ frame'de bir kaydet
    """
    os.makedirs(output_dir, exist_ok=True)
    
    cap = cv2.VideoCapture(video_path)
    frame_count = 0
    saved_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        if frame_count % interval == 0:
            filename = f"frame_{saved_count:06d}.jpg"
            cv2.imwrite(os.path.join(output_dir, filename), frame)
            saved_count += 1
        
        frame_count += 1
    
    cap.release()
    print(f"Saved {saved_count} frames")

# KullanÄ±m
extract_frames("video.mp4", "data/datasets/images/raw", interval=30)
```

### 2. CanlÄ± Kameradan KayÄ±t

```python
import cv2
import time

def capture_training_images(camera_source, output_dir, num_images=100, interval=2):
    """
    Kameradan eÄŸitim gÃ¶rÃ¼ntÃ¼leri toplar.
    """
    os.makedirs(output_dir, exist_ok=True)
    
    cap = cv2.VideoCapture(camera_source)
    count = 0
    
    print("Press 's' to save, 'q' to quit")
    
    while count < num_images:
        ret, frame = cap.read()
        if not ret:
            continue
        
        cv2.imshow("Capture", frame)
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('s'):
            filename = f"capture_{count:04d}.jpg"
            cv2.imwrite(os.path.join(output_dir, filename), frame)
            print(f"Saved: {filename}")
            count += 1
        elif key == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
```

---

## ğŸ·ï¸ Veri Etiketleme

### Ã–nerilen AraÃ§lar

1. **LabelImg** - Basit ve Ã¼cretsiz
   ```bash
   pip install labelImg
   labelImg
   ```

2. **CVAT** - Web tabanlÄ±, geliÅŸmiÅŸ Ã¶zellikler
   ```bash
   docker run -p 8080:8080 cvat/server
   ```

3. **Roboflow** - Online, otomatik augmentation
   - https://roboflow.com

### LabelImg KullanÄ±mÄ±

1. LabelImg'i aÃ§Ä±n
2. "Open Dir" ile gÃ¶rÃ¼ntÃ¼ klasÃ¶rÃ¼nÃ¼ seÃ§in
3. "Change Save Dir" ile label klasÃ¶rÃ¼nÃ¼ seÃ§in
4. Format olarak "YOLO" seÃ§in
5. Her gÃ¶rÃ¼ntÃ¼ iÃ§in:
   - 'w' tuÅŸu ile dikdÃ¶rtgen Ã§izin
   - SÄ±nÄ±f seÃ§in
   - Kaydedin (Ctrl+S)

### Etiketleme Ä°puÃ§larÄ±

- **TutarlÄ±lÄ±k:** AynÄ± nesneyi her zaman aynÄ± ÅŸekilde etiketleyin
- **TÃ¼m Nesneler:** GÃ¶rÃ¼ntÃ¼deki tÃ¼m hedef nesneleri etiketleyin
- **SÄ±kÄ± Bounding Box:** Nesneyi sÄ±kÄ±ca sarÄ±n, fazla boÅŸluk bÄ±rakmayÄ±n
- **Zor Ã–rnekler:** KÄ±smen gÃ¶rÃ¼nen, kalabalÄ±k, belirsiz nesneleri dahil edin

---

## ğŸ”„ Veri Augmentation

### Otomatik Augmentation

```python
# config/model_config.yaml

training:
  augmentation:
    enabled: true
    horizontal_flip: true
    vertical_flip: false
    rotation: 15
    scale: [0.8, 1.2]
    brightness: 0.2
    contrast: 0.2
    mosaic: true
    mixup: 0.1
```

### Manuel Augmentation

```python
import albumentations as A
import cv2

transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.Rotate(limit=15, p=0.5),
    A.GaussNoise(p=0.3),
    A.Blur(blur_limit=3, p=0.2),
], bbox_params=A.BboxParams(format='yolo'))

# KullanÄ±m
image = cv2.imread("image.jpg")
bboxes = [[0.5, 0.5, 0.3, 0.4, 0]]  # YOLO format + class

transformed = transform(image=image, bboxes=bboxes)
aug_image = transformed['image']
aug_bboxes = transformed['bboxes']
```

---

## ğŸš€ Model EÄŸitimi

### Basit EÄŸitim

```python
from ultralytics import YOLO

# Pretrained model yÃ¼kle
model = YOLO('yolov8n.pt')

# EÄŸit
results = model.train(
    data='data/datasets/dataset.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    name='animal_detector'
)
```

### GeliÅŸmiÅŸ EÄŸitim

```python
from ultralytics import YOLO

model = YOLO('yolov8s.pt')

results = model.train(
    # Veri
    data='data/datasets/dataset.yaml',
    
    # EÄŸitim parametreleri
    epochs=150,
    patience=30,  # Early stopping
    batch=16,
    imgsz=640,
    
    # Optimizer
    optimizer='AdamW',
    lr0=0.001,
    lrf=0.01,  # Final learning rate
    momentum=0.9,
    weight_decay=0.0005,
    
    # Augmentation
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    degrees=15,
    translate=0.1,
    scale=0.5,
    fliplr=0.5,
    mosaic=1.0,
    mixup=0.1,
    
    # DiÄŸer
    device='auto',
    workers=8,
    project='runs/train',
    name='animal_detector_v1',
    exist_ok=False,
    pretrained=True,
    verbose=True,
    save=True,
    save_period=10,
)
```

### Komut SatÄ±rÄ±ndan EÄŸitim

```bash
yolo train \
    data=data/datasets/dataset.yaml \
    model=yolov8s.pt \
    epochs=100 \
    imgsz=640 \
    batch=16 \
    name=animal_detector
```

---

## ğŸ“Š Model DeÄŸerlendirme

### Validasyon

```python
from ultralytics import YOLO

model = YOLO('runs/train/animal_detector/weights/best.pt')

# Validasyon
metrics = model.val(data='data/datasets/dataset.yaml')

print(f"mAP50: {metrics.box.map50:.4f}")
print(f"mAP50-95: {metrics.box.map:.4f}")
print(f"Precision: {metrics.box.p:.4f}")
print(f"Recall: {metrics.box.r:.4f}")
```

### Test GÃ¶rÃ¼ntÃ¼leri ile Test

```python
# Tek gÃ¶rÃ¼ntÃ¼
results = model.predict('test_image.jpg', conf=0.5)

# KlasÃ¶r
results = model.predict('data/datasets/images/test/', conf=0.5, save=True)
```

### Confusion Matrix

```python
# Validasyon sonrasÄ± otomatik oluÅŸturulur
# runs/train/animal_detector/confusion_matrix.png
```

---

## ğŸ’¾ Model Export

### ONNX Export

```python
from ultralytics import YOLO

model = YOLO('runs/train/animal_detector/weights/best.pt')

# ONNX export
model.export(format='onnx', dynamic=True, simplify=True)
```

### TensorRT Export (NVIDIA GPU)

```python
model.export(format='engine', device=0, half=True)
```

### DiÄŸer Formatlar

```python
# CoreML (iOS/macOS)
model.export(format='coreml')

# TensorFlow Lite (Mobile)
model.export(format='tflite')

# OpenVINO (Intel)
model.export(format='openvino')
```

---

## ğŸ“ˆ EÄŸitim Ä°zleme

### TensorBoard

```bash
# EÄŸitim sÄ±rasÄ±nda
tensorboard --logdir runs/train

# TarayÄ±cÄ±da aÃ§
# http://localhost:6006
```

### Weights & Biases

```python
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

# W&B ile eÄŸitim
model.train(
    data='dataset.yaml',
    epochs=100,
    project='animal-tracking',
    name='experiment-1'
)
```

---

## ğŸ”§ Hiperparametre Ayarlama

### Otomatik Tuning

```python
from ultralytics import YOLO

model = YOLO('yolov8n.pt')

# Ray Tune ile hyperparameter search
model.tune(
    data='data/datasets/dataset.yaml',
    epochs=30,
    iterations=50,
    optimizer='AdamW',
    plots=True,
    save=True
)
```

### Manuel Deneyler

```python
experiments = [
    {'lr0': 0.001, 'batch': 16},
    {'lr0': 0.0001, 'batch': 16},
    {'lr0': 0.001, 'batch': 32},
]

for i, params in enumerate(experiments):
    model = YOLO('yolov8n.pt')
    model.train(
        data='dataset.yaml',
        epochs=50,
        name=f'exp_{i}',
        **params
    )
```

---

## ğŸ“ En Ä°yi Uygulamalar

### Veri

1. **En az 500-1000 gÃ¶rÃ¼ntÃ¼** sÄ±nÄ±f baÅŸÄ±na
2. **%80/%10/%10** train/val/test oranÄ±
3. **Ã‡eÅŸitlilik:** FarklÄ± aÃ§Ä±lar, Ä±ÅŸÄ±k, arka plan
4. **Dengeleme:** SÄ±nÄ±flar arasÄ± dengesizliÄŸi giderin

### EÄŸitim

1. **Pretrained model** ile baÅŸlayÄ±n
2. **DÃ¼ÅŸÃ¼k learning rate** (0.001 veya altÄ±)
3. **Early stopping** kullanÄ±n
4. **Augmentation** mutlaka uygulayÄ±n
5. **Batch size:** GPU belleÄŸine gÃ¶re maksimize edin

### DeÄŸerlendirme

1. **Test seti** eÄŸitimde hiÃ§ kullanÄ±lmamalÄ±
2. **mAP50-95** ana metrik olarak kullanÄ±n
3. **Confusion matrix** analiz edin
4. **GerÃ§ek ortamda** test edin

---

## ğŸ› Sorun Giderme

### Overfitting

- Daha fazla veri toplayÄ±n
- Augmentation artÄ±rÄ±n
- Dropout/regularization ekleyin
- Daha kÃ¼Ã§Ã¼k model kullanÄ±n

### Underfitting

- Daha bÃ¼yÃ¼k model kullanÄ±n
- Daha uzun eÄŸitin
- Learning rate ayarlayÄ±n

### DÃ¼ÅŸÃ¼k DoÄŸruluk

- Veri kalitesini kontrol edin
- Etiketleme hatalarÄ±nÄ± dÃ¼zeltin
- SÄ±nÄ±f dengesizliÄŸini giderin

### CUDA Bellek HatasÄ±

- Batch size azaltÄ±n
- GÃ¶rÃ¼ntÃ¼ boyutunu kÃ¼Ã§Ã¼ltÃ¼n
- Gradient checkpointing kullanÄ±n

---

## ğŸ“š Kaynaklar

- [Ultralytics Docs](https://docs.ultralytics.com/)
- [YOLOv8 GitHub](https://github.com/ultralytics/ultralytics)
- [Roboflow Blog](https://blog.roboflow.com/)
- [Papers With Code - Object Detection](https://paperswithcode.com/task/object-detection)
